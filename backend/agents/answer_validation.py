import re
import pandas as pd
import numpy as np
from langchain.prompts import PromptTemplate
from langchain_core.messages import HumanMessage
from langchain_groq import ChatGroq
from typing import Dict, Any

class AnswerValidation:
    """Validates query execution results by recomputing with an alternative method."""

    def __init__(self, groq_api_key):
        self.llm = ChatGroq(model="llama3-70b-8192", temperature=0, groq_api_key=groq_api_key)

    def validate_result(self, df: pd.DataFrame, query: str, executed_code: str, result: Any) -> Dict:
        """Generates an alternative validation method to verify query results and provides a justification."""

        validation_prompt = PromptTemplate.from_template(
            """You are a Python data validation expert. Your task is to generate an alternative Pandas command 
            to validate the following query result.

            - Use the DataFrame variable `df` (already provided).
            - Ensure the output is stored in a variable called `validation_result`.
            - Use the **same aggregation logic** as the original executed code.
            - If the result is a **numeric value**, allow a small tolerance of Â±0.01 for rounding differences.
            - If the result is a **DataFrame or Series**, ensure the column order and data types match.
            - Do not include explanations, markdown, or extra text.

            User Query: {query}
            Original Executed Code:
            ```python
            {executed_code}
            ```

            Example Output (for scalar results):
            ```python
            validation_result = df["Sales"].sum()
            ```

            Example Output (for DataFrame results):
            ```python
            validation_result = df.groupby('Category')['Sales'].sum()
            ```
            """
        )

        validation_message = validation_prompt.format_prompt(query=query, executed_code=executed_code)
        validation_response = self.llm.invoke([HumanMessage(content=validation_message.to_string())])
        validation_code = validation_response.content.strip()

        # âœ… Extract only Python code (Removes markdown formatting)
        match = re.search(r"```python(.*?)```", validation_code, re.DOTALL)
        if match:
            validation_code = match.group(1).strip()

        # âœ… Ensure the LLM response starts with 'validation_result ='
        if not validation_code.startswith("validation_result ="):
            return {
                "validation_status": "error",
                "validation_message": "Invalid validation code generated by LLM.",
                "validation_code": validation_code
            }

        # âœ… Execute validation code safely
        local_vars = {"df": df, "pd": pd, "np": np}
        try:
            exec(validation_code, globals(), local_vars)
            validation_result = local_vars.get("validation_result")
        except Exception as e:
            return {
                "validation_status": "error",
                "validation_message": f"Error executing validation code: {str(e)}",
                "validation_code": validation_code
            }

        # âœ… Retrieve and compare results safely
        is_valid = False

        # âœ… Handle DataFrame/Series comparison
        if isinstance(result, pd.DataFrame) and isinstance(validation_result, pd.DataFrame):
            is_valid = result.equals(validation_result)
        elif isinstance(result, pd.Series) and isinstance(validation_result, pd.Series):
            is_valid = result.equals(validation_result)
        
        # âœ… Handle scalar values with tolerance for rounding differences
        elif isinstance(result, (int, float)) and isinstance(validation_result, (int, float)):
            is_valid = abs(result - validation_result) <= 0.01  # âœ… Allow small floating-point differences
        
        # âœ… Handle exact match for strings
        elif isinstance(result, str) and isinstance(validation_result, str):
            is_valid = result.strip().lower() == validation_result.strip().lower()

        else:
            is_valid = False  # Mismatched data types

        # âœ… Debugging information for mismatched results
        if not is_valid:
            print("Original Query Result:", result)
            print("Validation Query Result:", validation_result)

        # **ðŸ”¹ Generate a Justification for the Validation Status**
        justification_prompt = PromptTemplate.from_template(
            """Explain in a short and concise manner why the validation result is {status}.
            
            - Use simple language to summarize the logic behind the query.
            - Use simple language to highlight key insights from the result.
            - Mention specific values, trends, or categories where applicable.
            - Keep it under 100 words.
            - Do not include Python code, just the explanation

            User Query: {query}
            Executed Code:
            ```python
            {executed_code}
            ```

            Ensure the justification is **relevant to the result type** and **references the key data points from the result**.
            """
        )

        justification_message = justification_prompt.format_prompt(
            status="valid" if is_valid else "invalid", query=query, executed_code=executed_code
        )
        justification_response = self.llm.invoke([HumanMessage(content=justification_message.to_string())])
        justification = justification_response.content.strip()

        return {
            "validation_status": "valid" if is_valid else "invalid",
            "validation_message": "Results match the validation method." if is_valid else 
                                  "Results do not match the alternative validation method.",
            "validation_code": validation_code,
            "computed_validation_result": validation_result,
            "justification": justification  # âœ… Added justification for validation
        }
